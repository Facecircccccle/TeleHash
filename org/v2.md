telehash v2 (draft)
===================

# Introduction

(note: this is the second major version of the telehash protocol, the first one is deprecated and was a minimal experimental spec to create a distributed hash table, it is a work in progress yet and unstable!)

Telehash is a new encrypted mesh protocol enabling applications to find, identify, and communicate directly with each other.  It is built on public-key security (PKI) and fundamentally creates peer-to-peer (P2P) connections using a distributed hash-table (DHT) to form the mesh.  As a protocol it doesn't provide direct end-user functionality (you won't find "client apps" here) but is primarily a tool for developers (specs and libraries/SDKs) to use in creating modern apps that require rich experiences and private interconnectivity at scale.

The principle idea that drove the creation and development of telehash is the belief that any app should be able to easily and securely talk to any other app (either two instances of the same app or between completely different apps) directly and in any environment (servers, mobile, sensors, etc).  By enabling this freedom for developers as a foundation for their apps it then enables the same freedom for the people using them, that they can connect, share, and communicate privately more easily.

The challenges and complexity right now in connecting apps via existing technologies such as APIs, OAuth, and REST is only increasing, often forcing fundamentally insecure centralized and closed/gated communication platforms.  By adopting telehash in any app it immediately has a powerful set of open tools for not only its own needs, but can then also enable connectivity to and from apps created by others easily. These tools include the ability to have friends, sharing, feeds, tagging, search, notifications, discovery, and other social patterns.

The foundation of the protocol builds on JSON as the core extensible data format with a requirement to keep it simple and lightweight enough to support apps running on networked devices and sensors. The design goals include not forcing any particular architecture design such as client-server, centralized/federated/distributed, polling/push, REST, streaming, publish-subscribe, or message passing... any can be used as telehash simply facilitates creating the bi-directional connectivity between any two or more apps.

There's some high level concepts that are important to understand when talking about anything using telehash, and the first one is that of a "network", the term describing how all telehash apps are organized.  A network is identified by it's hostname (such as "telehash.org" is one network) and is the primary form of trust and connectivity between apps.  Each network is it's own DHT and has one or more "operators" which facilitate access to other apps in the network (act as a seed), and can provide other administrative services depending on the app.

Every instance of an app has a unique public id on each network it's connected to that is called it's "hashname" and is the primary means of finding and communicating with other instances in the network. Any app may have one or more networks that it's connected to, including private ones for app-specific services and public ones that are providing functionality to many apps.

# Getting Started

In order to use telehash in an app it will need to include a switch, the software layer that talks to the network and processes packets.  Each unique instances of an app must also generate or have it's own private RSA key-pair, which is used to used to create it's hashname(s) and encrypt the data sent on any network.  Once it's connected it can find and access other hashnames as well as provide services to back out to anyone on that network.  

Most apps will need their own network for access to their back-end, user management, profiles, notifications, etc facilities. To create a new network you simply need to add a DNS SRV record to the hostname for your network that identifies one or more hashnames of operators that manage it.  (todo show example operators, software and patterns)

## Telehash Switches

The software implementations of the telehash protocol are called a "switch" and it's highly suggested to use an existing switch library or service for your platform or language versus trying to create one from scratch in order to ensure that the security and identity aspects are verified properly. If there isn't one yet then we'd love your help, pull requests to list them here are welcome!

* Node.js - [node-telehash](http://github.com/quartzjer/node-telehash)

---

# Protocol Details

## Vocab

* DHT - Distributed Hash Table (based on [Kademlia](http://en.wikipedia.org/wiki/Kademlia))
* NAT - A device/router that acts as a bridge to internal IPPs (Network Address Translation)
* Hashname - The unique ID of an individual application/instance using telehash
* Packet - A UDP packet less than 1400 bytes sent between any hashnames
* Switch - The name of the software layer or service parsing packets for one or more hashnames
* Network - A unique name representing a collection of hashnames that form a unique single DHT
* Line - When any two hashnames connect and exchange their identity to form a temporary encrypted session

### Hashnames

Every endpoint within telehash is identified by it's hashname, a 40-character SHA1 string that is created by hashing the PEM-formatted RSA public key concatenated with the hostname of the network being used.

Example of how to create a hashname:
``` js
	var key = "-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEArq38dvKzL5W2QqprgQN7\nAo5OWFhX04aIrYZH5sLjOzyI0gWZ6ZzpQifRk+L1yNU3nkotKfeQF5zzZvo4F7YL\nC4fZgkCN2TnvBihKj25CHVDKLOtV01LvPvEEX+oHQyUzT90FT5UUIdOqTXHY4yT+\nnoxubQOAMSOsJHulpIMeDR+hPWYuZ5eZWfRimu0vEE1ujAeKGUk5avKtNtJIRDXB\nRRem/CBLPG5QRe+54w94Xwp1l3VQdJaD+qRKBEG/hhSVqUHfRqVccNR4AV+q37XG\nDAupGc7YUJ6Pqnj7TnapQGrSno13IG+2PIhL3gB1lMWEGE/hwN1dxuUAXXsIgPU3\nKwIDAQAB\n-----END PUBLIC KEY-----\n";
	var network = "telehash.org";
	var hashname = require("crypto").createHash("sha1").update(key + network).digest('hex');
```

Since the DHT is based on Kademlia this makes a [Sybil attack](http://en.wikipedia.org/wiki/Sybil_attack) more difficult, but not impossible, particularly for smaller networks.  Each network needs to use additional mechanisms (such as social ones assisted by the app layer) to ensure that the hashnames joining it's DHT are not being maliciously created.

### Networks

A network is simply a collection of apps that have a pre-known relationship or some trust each other and is typically an app or service's domain name, like "telehash.org".

All hashnames that are part of a network must have a seed list in order to join/create the DHT.  This list of seeds must contain at least an IP, Port, and the Public Key for each seed entry in order for the hashname to connect to them when starting.  The seed list may also change over time to include new stable or trusted hashnames in that network.

## Parsing

Every packet must begin with two bytes that are a short unsigned integer representing the length of bytes that follow it.  That length of bytes are UTF8 encoded JSON and can be parsed by any JSON parser.  The JSON is required so the length must be greater than two (the minimum JSON "{}" string) and less than the length of the raw UDP message minus two (the bytes for the short unsigned integer). Any remaining bytes on the packet are considered raw binary and referenced as the 'BODY' when used in definitions below.

    <length><JSON>[BODY]

Example decoding logic in node (simplified):
``` js
dgram.createSocket("udp4", function(msg){
	var length = msg.readUInt16BE(0);
    var js = JSON.parse(msg.toString("utf8", 2, length + 2));
	var body = msg.slice(length + 2);
});
```

It is a very common pattern for multiple packets to be included in one UDP message recursively, where the BODY is actually another packet, so switch implementations must be prepared to decode a packet generically on demand from a set of raw bytes.

### JSON

The JSON often acts as the header for a packet that has a binary payload, or can be the entire thing.  The fields used vary depending on the context and are specified below, but all initial packets contain a "type" field with a string value.


### BODY

The optional BODY is always a raw binary of the remainder bytes between the packet's total length and that of the JSON as indicated by LENGTH above. Often a BODY is another full raw packet and will be decoded identically to being read from the UDP socket, this pattern of one packet enclosing/attaching another is how the RSA signatures and encryption are implemented.

The BODY is also used as the raw (optionally binary) content transport for streams and for any app-specific usage.

# Packet Processing

When a packet is being processed from a UDP message initially, it's JSON must contain a "type" field with a string value of "open" or "line", each of which determine how to process the BODY of the packet:

* [open](#open) - this is a request to establish a new encrypted session (a `line`) and contains the data to do so
* [line](#line) - this is an encrypted packet for an already established session

Once a line is established, all packets sent thereafter within a line will contain a [stream](#stream) as the content-transport method between any two hashnames.

<a name="open" />
## `open` - Establishing a Line

A packet of `"type":"open"` is used to establish a temporary encrypted session between any two hashnames, this session is called a "line". Every open packet requires the JSON keys of "open", "iv", and "sig", here's an example of the JSON part of the packet:
```js
{
	"type":"open",
	"open":"ZkQklgyD91XQaih07VBUGeQmAM9tnR5qMGMavZ9TNqQMCVfTW8TxDr9y37cgB8g6r9dngWLjXuRKe+nYNAG/1ZU4XK+GiR2vUBS8VTcAMzBcUls+GIfZU6WO/zEIu4ra1I1vI8qnYY5MqS/FQ/kMXk9RyzERaD38IWZLk3DYhn8VYPnVnQX62mE5u20usMWQt99F8ITLy972nOhdx5y9RUnnSrtc1SD9xr8O0rco22NtOEWC3uAISwC9xuihT+U7OEcvSKolScFI4oSpRu+DQWl19EAuG9ACqhs5+X3qNeBRMSH8w5+ThOVHaAWKGfFs/FNMdAte3ki8rFesMtfhXQ==",
	"iv":"60aa6514ef28178f816d701b9d81a29d",
	"sig":"o6buYor8o3YXkPIDJjufn9udfWDJt5hrgnVtKtvZI2ObOPlPSqlb2AdH6QsC7CuwtboGlt6eMbE7Ep6Js2CXeksXTCSZOJ99US7TH0kZ1H1aDqxYpQlM6BADOjG6YOcW+EhniotNUBiw3r02Xt4ohSm0wXxQ97JM95ntFBRnWr1vG25d+5pJQE4LyN2TwB4uApu9zeUoTPhF7daJQOcIMn9en+XxyuBsG61oR/x29bpaoZJGnKrk2DGH1jDnI5GpxIKUbT/Pa7QOlrICUCjGDgxy2TMQ+fiip5sIflxtFUPM/BV9mh4K7/ZaekJXTFfG2FKvJFytQkWbisDVy5EbEA=="
}
And the BODY will be a binary encrypted blob, the contents of which (after decryption) is another packet with the sender's RSA public key as the BODY attachment and the JSON being:
```js
{
	"to":"dc375b4fc180d03fee8748ee71c2ec5c4d90bb63",
	"at":1375983687346,
	"line":"c4e9b78d6bf2732d9f8532193102e6dfe5410f62"
}
```

The original open packet's required values are defined as:

* `open` - a base64 string value that is is created by generating a new elliptic (ECC) public key using the nistp256 curve, and using RSA to encrypt it (PKCS OAEP padding) *to* the recipients RSA public key.
* `iv` - 16 random bytes hex encoded
* `sig` - a base64 string created using the sender's RSA public key to sign (HMAC-SHA256) the attached (encrypted) binary body.

And the attached packet's required values are defined as:

* `to` - which hashname this line is being created to
* `line` - the unique id the recipient must use for sending any line packets, a 40 length hex value (SHA1)
* `at` - an integer timestamp of when it was sent, used to another open request is newer

To process an open packet, the recipient must first decrypt the "open" value using their RSA private key, and the binary result of that decryption will be the sender's temporary elliptic curve public key.  That ECC key is then hashed using SHA256, these resulting 32 bytes are then used as the AES key along with the random 16 bytes decoded from the hex value of the "iv" from the JSON as the initialization vector to decipher the included binary body using AES-256-CTR. 

Once the attached BODY is unencrypted, it is then decoded as another packet with the JSON values above and a BODY of the sender's RSA public key.  That RSA public key is then used to validate the value of the "sig" in the open packet.

With the decrypted and verified information, the recipient can now also return an open packet (if it hasn't already sent one) and use Diffie-Hellman to derive a shared secret (ECDHE) from the elliptic key it generated for this line along with the public elliptic key it received.  

Example open packet generation logic in node (simplified):
```js
var eccSession = new eccKey("nistp256");

var attached = {js:{}, body:myRSAPublicKey};
attached.js.to = recipientHashname;
attached.js.at = Date.now();
attached.js.line = crypto.randomBytes(20).toString("hex");
var attachedRaw = packetEncode(attached);

var open = {js:{type:"open"}};
open.js.open = rsa(recipientRSAPublicKey).encrypt(eccSession.PublicKey, "PKCS1_OAEP_PADDING").toString("base64");

var aesKey = crypto.createHash('sha256').update(eccSession.PublicKey).digest();
var aesIV = crypto.randomBytes(16);
var aesCipher = crypto.createCipheriv("AES-256-CTR", aesKey, aesIV);
open.body = Buffer.concat([aesCipher.update(attachedRaw), aesCipher.final()]);
open.js.iv = aesIV.toString("hex");
open.js.sig = crypto.createSign("RSA-SHA256").update(open.body).sign(myRSAPrivateKey, "base64");

var openRaw = packetEncode(open);
```

Example open packet validation logic in node (simplified):
```js
// generate these to identify the line being created for each sender
var myEccSession = new eccKey("nistp256");
var myLineId = crypto.randomBytes(20).toString("hex");

var packet = packetDecode(openRaw);

var open = rsa(myRSAPrivateKey).decrypt(packet.js.open, "base64", "PKCS1_OAEP_PADDING");
var senderEccPublicKey = new eccKey("nistp256", open);

var aesKey = crypto.createHash('sha256').update(open).digest();
var aesIV = new Buffer(packet.js.iv, "hex");
var aesDecipher = crypto.createDecipheriv("AES-256-CTR", aesKey, aesIV);
var attached = packetDecode(Buffer.concat([aesDecipher.update(packet.body), aesDecipher.final()]));

if(attached.js.to !== self.hashname) return; // must match recipients hashname

var senderRSAPublicKey = deciphered.body.toString("utf8");
var valid = crypto.createVerify("RSA-SHA256").update(packet.body).verify(senderRSAPublicKey, packet.js.sig, "base64");

// generate the aes session key used for all of the line encryption
var ecdheSecret = myEccSession.deriveSharedSecret(senderEccPublicKey);
var lineEncryptKey = crypto.createHash("sha256")
  .update(ecdheSecret)
  .update(new Buffer(myLineId, "hex"))
  .update(new Buffer(attached.js.line, "hex"))
  .digest();
var lineDecryptKey = crypto.createHash("sha256")
  .update(ecdheSecret)
  .update(new Buffer(attached.js.line, "hex"))
  .update(new Buffer(myLineId, "hex"))
  .digest();
```

<a name="line" />
## `line` - Packet Encryption

A packet with a `"type":"line"` is only sent/valid after an open has been exchanged, and is required to have a `"line":"3ec1e50ad96e1895a3ed640c908ec78546e29816"` with the value being the same as the recipient sent in it's open and a random `"iv":"9c23429f8156..."` used for the AES encryption.  This ensures that no line packets can be received without being invited in an open. Any unknown ones are just ignored.

The BODY is a binary encoded encrypted packet using AES-256-CTR with the key that was generated for the line and the 16-byte initialization vector decoded from the included "iv" hex value.  Once decrypted, the recipient then processes it as a normal packet (LENGTH/JSON/BODY) from the sending hashname.  All decrypted packets must contain a `"stream":"2588f32b66ac88cb4d02a78d62d1671814b18b82"` value as defined below.

<a name="stream" />
## `stream` - Content Transport

All data sent between any two hashnames (inside a line packet) must contain a `"stream":"2588f32b66ac88cb4d02a78d62d1671814b18b82"` with a unique 40 length hex value (SHA1) determined by the sender for each different exchange or channel.  A stream always begins with a `"type":"..."` to tell the recipient what kind of stream it is, and may not have any response, or may be long-lived with many packets exchanged using the same "stream" identifier (depending on the type of stream). At any point a stream can be closed by sending an `"end":true`, and if it was an error a string message can be included as the value of the `"err":"message"`.

The following values for `type` are part of the core spec that all switches must implement:

* [seek](#seek) - return any pointers to other closer hashnames for the given `hash` (DHT), answer contains `see`
* [peer](#peer) - ask the recipient to make an introduction to one of it's peers
* [connect](#connect) - a request asking to try to open a connection to a given hashname (result of a `peer`)

Additional `type` values can be defined by any application as long as they begin with an underscore like `"type":"_custom"`.  Common patterns are also being defined as extensions, such that switches can start to support them internally easily:

* [sockets](ext_sockets.md) - raw socket proxy/transport
* [tickets](ext_tickets.md) - a way to create portable data containers that are signed by a hashname

All UDP packets are by their very nature lossy so streams also inherently supports reliability, retransmission, and buffering/backpressure mechanisms by requiring a lightweight `"seq":0` field on every packet. All seq values start at 0 and increment per packet sent. A buffer of these packets must be kept keyed by the seq value until the receiving hashname has responded confirming them in a `ack` and not in the `miss`. The `ack` is the highest known `seq` value received. The `miss` is an array of integers and must be sent along with any `ack` if in the process of receiving packets there were any missing sequences, containing in any order the missing sequence values up to the `ack`.  Upon receipt those missed packets should be resent verbatim.

By default a stream should be invalidated if a sequence has been missed three or more times, or there's more than 100 missed packets by default (senders cannot send more than that without a confirming range). When there's consistently missing packets, senders should limit the number of packets beyond the confirmed range. (needs more examples/definition)

When reliability isn't required for a stream, either side can send an `ack` of the last received `seq` value without tracking any misses, while still following the 100-max-outstanding rule to provide for any congestion/loss detection.

<a name="seek" />
### `"type":"seek"` - Finding Hashnames (DHT)

Every network is also a basic Kademlia-based DHT. The bulk of the complexity is in the rules around maintaining a mesh of lines and calculating distance explained [below](#kademlia). The `"seek":"15f4af33b7edcfbc716cd733a9ed73cc3033c17f"` value is always another hashname that the app is trying to connect to.

When one hashname wants to connect to another hashname, it finds the closest lines it knows and sends a `seek` containing the hash value to them.  They return a compact `"see":[...]` array of addresses that are closest to the hash value.  The addresses are a compound comma-delimited string containing the "hash,ip,port" (these are intentionally not JSON as the verbosity is not helpful here), for example "a9993e364706816aba3e25717850c26c9cd0d89d,123.45.67.89,10111". 

<a name="peer" />
### `"type":"peer"` - Introductions to new hashnames

For any hashname to send an open to another it must first have it's hashname, so there is a two step process starting with a peer request. Since new hashnames are discovered only from another (in the `see` values), they are tracked as a "via" so that they can be sent a peer request when a connection is being made to a hashname they sent.

This also serves as a workaround if any NAT exists, so that the two hashnames can send a packet to each other to make sure the path between them is open, this is called "hole punching." A peer request requires a `"peer":[...]` where the value is an array of hashnames the sender is trying to reach. The recipient of the peer request must then send a connect (below) to each of the target hashnames (that it already must have an open line to).

<a name="connect" />
### `"type":"connect"` - Connect to a hashname

The connect request is an immediate result of a peer request and must also contain an `"ip":"1.2.3.4"` and `"port":5678` with the values being of the peer requestor and a BODY of their public key.

The recipient can use the given IP, port, and public key to send an open request to the target.  If a NAT is suspected to exist, the target should have already sent a packet to ensure their side has a path mapped through the NAT and the open should then make it through.

# Switch Behaviors

Besides parsing the protocol, decoding the packets and processing the different stream types, in order to fully implement telehash a switch must also internally track and respond with the correct behaviors to support both the DHT for a network and manage the reliability of streams that require it.

<a name="kademlia" />
## [Kademlia](http://en.wikipedia.org/wiki/Kademlia)

(this area in progress...)

Every switch must have both a startup/seeding routine, and a background line maintenance process in order to properly support the Kademlia-based DHT for each network it's attached to.

The core data structure to support this within a switch is a list of "buckets", one for each bit of distance between it's own hashname and every other hashname encountered, 160 of them.  These buckets can contain a variable number of hashnames each, but it's recommended for any switch to limit the size of each bucket to a reasonable number more than 1 and less than 10 so as to not consume too much memory or network resources maintaining lines.

The seeding process involves recursively performing a [seek](#seek) for it's own hashname against the list of seeds (provided by the app) or operators (as resolved via DNS).

The maintenance process involves tracking all the hashnames seen (result of any seek) and trying to ensure a line is open to the minimum number of hashnames in each bucket.

A new seek should be sent to every idle/inactive line at least once every 60 seconds if the switch believes it is behind a NAT (to maintain the NAT mapping), or once every hour if it knows it is not.  By seeking it's own hashname, any new hashnames near it will be returned to help maintain the DHT.

## Stream Congestion Control

(this area in progress...)

Reliability is optional for streams based on their type, each type must define if it requires it or not, and custom ones from the application must signal if they don't require it.

